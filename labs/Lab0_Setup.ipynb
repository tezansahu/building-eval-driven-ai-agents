{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "gwggq-CL9cdi",
      "metadata": {
        "id": "gwggq-CL9cdi"
      },
      "source": [
        "# Lab 0: Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d813c76c",
      "metadata": {
        "id": "d813c76c"
      },
      "source": [
        "**Objective**: Set up the development environment for building AI agents\n",
        "\n",
        "In this lab, you will:\n",
        "1. Install required Python packages\n",
        "2. Set up GitHub Models for free LLM access\n",
        "3. Deploy the mock backend using ngrok\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pAPA6lT_9jVp",
      "metadata": {
        "id": "pAPA6lT_9jVp"
      },
      "source": [
        "## Step 1: Install Required Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b8604f2",
      "metadata": {
        "id": "6b8604f2"
      },
      "source": [
        "We'll install all necessary Python packages for agent development.\n",
        "\n",
        "> You may see an error message like this at the bottom, but that's okay, as long as the call is successfully excuted (there a green tick next to the cell on the left):\n",
        "> ![image.png](https://i.ibb.co/nFVsYs4/python-package-download-error.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ff58cace",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ff58cace",
        "outputId": "d1a91a49-3406-4fde-be22-20685b665c71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m217.9/217.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.4/322.4 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.9/337.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m357.4/357.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m221.0/221.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m213.3/213.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m197.2/197.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.1/268.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m279.8/279.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m111.6/111.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.2/143.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m429.0/429.0 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m223.3/223.3 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m463.4/463.4 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install all required packages\n",
        "!pip install -q agent-framework --pre requests fastapi uvicorn pyngrok nest-asyncio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90Bk1_4k-UB7",
      "metadata": {
        "id": "90Bk1_4k-UB7"
      },
      "source": [
        "## Step 2: Configure GitHub Models Access with Colab Secrets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92619753",
      "metadata": {
        "id": "92619753"
      },
      "source": [
        "Instructions to Store Your GitHub Token Securely:\n",
        "\n",
        "**Step 2a: Get Your GitHub Personal Access Token (PAT)**\n",
        "1. Visit https://github.com/settings/tokens?type=beta\n",
        "2. Click \"Generate new token\" (fine-grained token)\n",
        "3. Set token name (e.g., \"GitHub Models Access\")\n",
        "4. Set expiration (e.g., 90 days)\n",
        "5. Under \"Permissions\", select \"Read access to content\"\n",
        "6. Click \"Generate token\" and **COPY THE TOKEN**\n",
        "\n",
        "**Step 2b: Store in Colab Secrets (Recommended)**\n",
        "1. Look at the left sidebar of this Colab notebook\n",
        "2. Click the **ğŸ”‘ key icon** (Secrets)\n",
        "3. Click **\"+ Add new secret\"**\n",
        "4. Name: `GITHUB_PAT`\n",
        "5. Value: **Paste your token here**\n",
        "6. Toggle **\"Notebook access\"** to ON\n",
        "\n",
        "![Colab Secrets Location](https://colab.research.google.com/img/colab_favicon_256px.png)\n",
        "\n",
        "**Why use Secrets?**\n",
        "- Tokens are encrypted and not visible in notebook cells\n",
        "- Prevents accidental token exposure when sharing notebooks\n",
        "- Follows security best practices\n",
        "\n",
        "**Note**: GitHub Models provides free access to various LLMs for development purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c7450376",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7450376",
        "outputId": "8b219f0f-be0f-4ef1-b5ae-5e9e9d91f416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… GitHub PAT loaded from Colab Secrets successfully!\n",
            "âœ… Token length: 93 characters\n"
          ]
        }
      ],
      "source": [
        "# Load GitHub token from Colab Secrets\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    GITHUB_PAT = userdata.get('GITHUB_PAT')\n",
        "    print(\"âœ… GitHub PAT loaded from Colab Secrets successfully!\")\n",
        "    print(f\"âœ… Token length: {len(GITHUB_PAT)} characters\")\n",
        "except Exception as e:\n",
        "    print(\"âš ï¸ WARNING: Could not load GITHUB_PAT from Colab Secrets!\")\n",
        "    print(\"   Please follow Step 2b above to add your token to Secrets.\")\n",
        "    print(f\"   Error: {e}\")\n",
        "    GITHUB_PAT = \"\"  # Fallback"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IgYt3V6f-hM_",
      "metadata": {
        "id": "IgYt3V6f-hM_"
      },
      "source": [
        "## Step 3: Test GitHub Models Connection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daf5ea3a",
      "metadata": {
        "id": "daf5ea3a"
      },
      "source": [
        "We'll test that we can connect to GitHub Models using the OpenAI Chat Completions API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0ydLaWlF2WtL",
      "metadata": {
        "id": "0ydLaWlF2WtL"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "JX928WpA2VmB",
      "metadata": {
        "id": "JX928WpA2VmB"
      },
      "outputs": [],
      "source": [
        "# Initialize OpenAI chat client with GitHub Models endpoint\n",
        "client = OpenAI(\n",
        "  base_url=\"https://models.github.ai/inference\",\n",
        "  api_key=GITHUB_PAT,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "DTdKvs-v2aH1",
      "metadata": {
        "id": "DTdKvs-v2aH1"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=\"openai/gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"What is in the meaning of life?\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    temperature=1.0,\n",
        "    top_p=1.0,\n",
        "    max_tokens=1000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f11f6bdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f11f6bdf",
        "outputId": "82a57506-5443-4885-fb9a-084db52801e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The meaning of life is a profound and complex question that has been contemplated by philosophers, scientists, and thinkers throughout history. Different cultures, religions, and individuals may offer varying interpretations. Generally, some common perspectives include:\n",
            "\n",
            "1. **Philosophical Perspectives**: Philosophers like existentialists suggest that life has no inherent meaning other than what we create for ourselves. Others, like utilitarians, may argue that the meaning of life is to maximize happiness and minimize suffering.\n",
            "\n",
            "2. **Religious Interpretations**: Many religions propose that the meaning of life is tied to a relationship with the divine, fulfilling a purpose set by a higher power, or preparing for an afterlife.\n",
            "\n",
            "3. **Scientific Views**: From a scientific standpoint, life can be seen as a product of evolutionary processes, with meaning derived from survival, reproduction, and the quest for knowledge and understanding.\n",
            "\n",
            "4. **Personal Meaning**: Ultimately, many people find meaning in personal relationships, experiences, accomplishments, and passions. This subjective approach allows individuals to define what is meaningful to them.\n",
            "\n",
            "In essence, the meaning of life may vary significantly from person to person, and many find that exploring this question leads to a deeper understanding of themselves and their place in the world.\n"
          ]
        }
      ],
      "source": [
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UgjOg_sl-lxK",
      "metadata": {
        "id": "UgjOg_sl-lxK"
      },
      "source": [
        "## Step 4: Download & Deploy Mock Backend with ngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e14728f6",
      "metadata": {
        "id": "e14728f6"
      },
      "source": [
        "We'll download the FastAPI backend from the repository and deploy it using ngrok to create a public URL.\n",
        "\n",
        "**What happens here:**\n",
        "- Downloads `mock_backend.py` from GitHub to Colab's `/content/` directory (default working directory)\n",
        "- Starts the FastAPI server in the background (runs on port 8000)\n",
        "- Creates a public URL via ngrok for external access\n",
        "- You can access the file at `/content/mock_backend.py` if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zf9k7OhG-ywH",
      "metadata": {
        "id": "Zf9k7OhG-ywH"
      },
      "source": [
        "### Step 4a: Download & Save the Mock Backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "OBsHDQkC6rJc",
      "metadata": {
        "id": "OBsHDQkC6rJc"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "szYseR4v6u9w",
      "metadata": {
        "id": "szYseR4v6u9w"
      },
      "outputs": [],
      "source": [
        "# Allow nested event loops (required for Colab)\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Download the mock backend from GitHub\n",
        "backend_url = \"https://raw.githubusercontent.com/tezansahu/building-eval-driven-ai-agents/main/backend/mock_backend.py\"\n",
        "\n",
        "print(\"ğŸ“¥ Downloading mock backend from repository...\")\n",
        "response = requests.get(backend_url)\n",
        "\n",
        "# Save to /content/ directory (Colab's default working directory)\n",
        "with open('mock_backend.py', 'w') as f:\n",
        "    f.write(response.text)\n",
        "\n",
        "print(\"âœ… Backend code downloaded to /content/mock_backend.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "jkMD3K9f7D-J",
      "metadata": {
        "id": "jkMD3K9f7D-J"
      },
      "outputs": [],
      "source": [
        "# Import the backend module\n",
        "import mock_backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "YmpeWcMG7HZG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmpeWcMG7HZG",
        "outputId": "e49687fe-e795-49cd-9946-e0d8b8abf92d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [422]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Starting FastAPI server...\n"
          ]
        }
      ],
      "source": [
        "# Start server in background thread\n",
        "print(\"ğŸš€ Starting FastAPI server...\")\n",
        "server_thread = mock_backend.run_in_thread(port=8000)\n",
        "time.sleep(2)  # Give server time to start\n",
        "\n",
        "print(\"âœ… FastAPI server started on port 8000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hr3wjVIAH6NS",
      "metadata": {
        "id": "Hr3wjVIAH6NS"
      },
      "source": [
        "### Step 4b: Configure ngrok Authentication"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bA345Ie77PA",
      "metadata": {
        "id": "0bA345Ie77PA"
      },
      "source": [
        "**ngrok requires a free account and authtoken for usage.**\n",
        "\n",
        "**Instructions:**\n",
        "1. Go to https://dashboard.ngrok.com/signup and create a free account\n",
        "2. After signup, go to https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "3. Copy your authtoken\n",
        "4. In Colab, click the **ğŸ”‘ key icon** (Secrets) on the left sidebar\n",
        "5. Click **\"+ Add new secret\"**\n",
        "6. Name: `NGROK_AUTHTOKEN`\n",
        "7. Value: **Paste your ngrok authtoken**\n",
        "8. Toggle **\"Notebook access\"** to ON\n",
        "\n",
        "**Why ngrok?** It creates a public URL for our local backend so the agent can access it from anywhere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "MMdS_ayA8SpE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMdS_ayA8SpE",
        "outputId": "569a4db9-d7ef-4934-bea6-253bf196e611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ngrok authenticated successfully!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    NGROK_AUTHTOKEN = userdata.get('NGROK_AUTHTOKEN')\n",
        "    ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "    print(\"âœ… ngrok authenticated successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"âš ï¸ WARNING: Could not load NGROK_AUTHTOKEN from Colab Secrets!\")\n",
        "    print(\"   Please follow the instructions above to add your ngrok authtoken.\")\n",
        "    print(f\"   Error: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "euaGcBppH_Me",
      "metadata": {
        "id": "euaGcBppH_Me"
      },
      "source": [
        "### Step 4c: Expose the Server Publicly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "z9lhDL0j7SL4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9lhDL0j7SL4",
        "outputId": "908be667-5aa9-4158-e2de-0d3c1e56c698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸŒ Creating public URL with ngrok...\n",
            "\n",
            "============================================================\n",
            "âœ… Backend server is running!\n",
            "============================================================\n",
            "ğŸ“¡ Public URL: https://a7e5f8bb2208.ngrok-free.app\n",
            "ğŸ“š API Docs: https://a7e5f8bb2208.ngrok-free.app/docs\n",
            "ğŸ“‚ File location: /content/mock_backend.py\n",
            "============================================================\n",
            "\n",
            "âš ï¸ IMPORTANT: Copy the Public URL above!\n",
            "   You'll need it for Lab 1 & Lab 2\n"
          ]
        }
      ],
      "source": [
        "# Create public URL with ngrok\n",
        "print(\"ğŸŒ Creating public URL with ngrok...\")\n",
        "public_url = ngrok.connect(8000)\n",
        "BACKEND_URL = public_url.public_url\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"âœ… Backend server is running!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"ğŸ“¡ Public URL: {BACKEND_URL}\")\n",
        "print(f\"ğŸ“š API Docs: {BACKEND_URL}/docs\")\n",
        "print(f\"ğŸ“‚ File location: /content/mock_backend.py\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nâš ï¸ IMPORTANT: Copy the Public URL above!\")\n",
        "print(f\"   You'll need it for Lab 1 & Lab 2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rgIWdpEzIkTq",
      "metadata": {
        "id": "rgIWdpEzIkTq"
      },
      "source": [
        "## Step 5: Test Backend API"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "111d2c25",
      "metadata": {
        "id": "111d2c25"
      },
      "source": [
        "Let's verify the backend is working correctly by testing the endpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "12788010",
      "metadata": {
        "id": "12788010"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Wx06nhRA8jOV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx06nhRA8jOV",
        "outputId": "00146c33-ad06-428e-a85a-a8c9cadabb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     34.48.100.192:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "Health Check: {'status': 'healthy', 'message': 'Campus Event Management API is running', 'endpoints': {'events': '/events', 'venues': '/venues', 'notifications': '/notifications', 'docs': '/docs'}}\n"
          ]
        }
      ],
      "source": [
        "# Test 1: Health check\n",
        "response = requests.get(f\"{BACKEND_URL}/\")\n",
        "print(\"Health Check:\", response.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Icc0Aqaq8lR6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Icc0Aqaq8lR6",
        "outputId": "e33b4f4b-1776-4d1d-aa6d-89bcab5d6957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     34.48.100.192:0 - \"GET /events HTTP/1.1\" 200 OK\n",
            "\n",
            "Found 4 events.:\n",
            "  - TechFest 2024 on 2024-03-15\n",
            "  - Spring Hackathon 2024 on 2024-04-20\n",
            "  - AI & Machine Learning Workshop on 2024-03-25\n",
            "  - Robotics Club Demo Day on 2024-04-05\n"
          ]
        }
      ],
      "source": [
        "# Test 2: List events\n",
        "response = requests.get(f\"{BACKEND_URL}/events\")\n",
        "events = response.json()\n",
        "print(f\"\\nFound {len(events)} events.:\")\n",
        "for event in events:\n",
        "    print(f\"  - {event['name']} on {event['date']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "N6kMi7FOIn1l",
      "metadata": {
        "id": "N6kMi7FOIn1l"
      },
      "source": [
        "## ğŸ‰ Lab 0 Complete!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-frXqnj-IryV",
      "metadata": {
        "id": "-frXqnj-IryV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "81770c32",
      "metadata": {
        "id": "81770c32"
      },
      "source": [
        "\n",
        "\n",
        "### What You Accomplished:\n",
        "\n",
        "âœ… **Installed Microsoft Agents Framework** - A high-level library for building AI agents  \n",
        "âœ… **Configured GitHub Models** - Free LLM access using GitHub PAT  \n",
        "âœ… **Stored secrets securely** - Using Colab Secrets (best practice)  \n",
        "âœ… **Deployed mock backend** - Campus event management API with ngrok  \n",
        "âœ… **Tested the setup** - Verified agent can call LLM and backend APIs\n",
        "\n",
        "### Key Concepts Learned:\n",
        "\n",
        "1. **Colab Secrets**: Secure way to store API tokens without exposing them in code\n",
        "2. **GitHub Models**: Free access to GPT-4o-mini for development\n",
        "3. **ngrok**: Makes local services accessible via public URL\n",
        "\n",
        "### What's Next?\n",
        "\n",
        "**Lab 1**: Build a complete campus event agent with 3 tools:\n",
        "- Register students for events\n",
        "- Book venues for clubs\n",
        "- Send notifications to participants\n",
        "\n",
        "**Lab 2**: Evaluate and improve the agent using metrics:\n",
        "- Relevance Evaluator (Azure AI)\n",
        "- Task Adherence Evaluator (Azure AI)\n",
        "- Custom Conciseness Evaluator\n",
        "- Measure improvement systematically\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YwfP6haEIyZy",
      "metadata": {
        "id": "YwfP6haEIyZy"
      },
      "source": [
        "## Troubleshooting:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yth8FXHQI0ga",
      "metadata": {
        "id": "yth8FXHQI0ga"
      },
      "source": [
        "**Issue**: \"Could not load GITHUB_PAT from Colab Secrets\"\n",
        "- **Solution**: Click ğŸ”‘ icon â†’ Add new secret â†’ Name: `GITHUB_PAT` â†’ Enable notebook access\n",
        "\n",
        "**Issue**: \"ngrok tunnel failed\"\n",
        "- **Solution**: Re-run the ngrok cell. Tunnels expire after inactivity.\n",
        "\n",
        "**Issue**: Backend API not responding\n",
        "- **Solution**: Check that BACKEND_URL is set correctly and starts with `https://`"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
